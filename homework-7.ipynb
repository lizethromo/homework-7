{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7: Optimization for physics\n",
    "\n",
    "**Due Friday, March 8**  \n",
    "\n",
    "*Enter your name here*  \n",
    "\n",
    "### Homework checklist\n",
    "\n",
    "Before submitting, make sure that you\n",
    "\n",
    "- Fill in your name in the space above\n",
    "- Cite any resources that you used while working on this homework\n",
    "- 1.a. Fill in the code to define the potential function  \n",
    "- 1.b. Fill in the code to plot the potential  \n",
    "- 2.a. Compute the derivative and fill in the code to evaluate it  \n",
    "- 2.b. Fill in the code for the steepest descent algorithm  \n",
    "- 3.a. Run the steepest descent algorithm\n",
    "- 3.b. Compare the results from 3.a. to your plot \n",
    "- 3.c. Run the steepest descent algorithm again with different initial conditions  \n",
    "- 3.d. Explain why we now get an incorrect answer, and how we could guard against this  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "This problem is derived from Example 6.5 in Newman's *[Computational Physics](http://www-personal.umich.edu/~mejn/cp/)* textbook.\n",
    "\n",
    "The [Buckingham potential](https://en.wikipedia.org/wiki/Buckingham_potential), \n",
    "\n",
    "$$V(r) = V_0 \\left[\\left(\\frac{\\sigma}{r}\\right)^6-e^{-r/\\sigma}\\right]\\,,$$\n",
    "\n",
    "is an approximate function for the potential energy between atoms at a distance $r$ from one another. This potential contains short-ranged repulsive and longer-ranged attractive terms. The net result is that the potential energy is minimized at an intermediate distance, for which there is no analytical expression. The goal of this homework assignment will be to numerically compute the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Visualize the potential\n",
    "\n",
    "First, let's see what the Buckingham potential looks like. For simplicity, we'll choose parameters $V_0=1$ and $\\sigma=1$. \n",
    "\n",
    "### 1.a. Define the function\n",
    "\n",
    "Fill in the code below to define a function, `buckingham`, that outputs the value of the potential as a function of the distance $r$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Write the function to evaluate the Buckingham potential\n",
    "\n",
    "def buckingham(r):\n",
    "    \"\"\" \n",
    "    Returns the value of the Buckingham potential at distance r.\n",
    "    Parameters V_0 and sigma are set to 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set V_0 and sigma\n",
    "    \n",
    "    V_0   = 1\n",
    "    sigma = 1\n",
    "    \n",
    "    # Evaluate the potential and return\n",
    "    \n",
    "    return  # FILL THIS IN (you may want to use np.exp for the exponential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b. Plot the potential curve\n",
    "\n",
    "Fill in the code below to plot the value of the potential over the range $[0.5, 4]$. We'll set the limits of the $y$ axis by hand so that the plot is not dominated by large values of the potential for small $r$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "r_values =  # FILL THIS IN\n",
    "V_values =  # FILL THIS IN\n",
    "\n",
    "sns.lineplot(r_values, V_values)\n",
    "plt.title(r'Buckingham potential')\n",
    "plt.ylim([-0.5, 0.5])\n",
    "plt.xlabel(r'$r$')\n",
    "plt.ylabel(r'$V$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up the optimization algorithm\n",
    "\n",
    "We'll use simple steepest descent to find the minimum of the Buckingham potential. You may want to refer back to lecture 15 for an example application. The steps of the algorithm are:\n",
    "\n",
    "1. Compute the direction of steepest descent $\\underline{s}$, given by the derivative $\\underline{s} = -\\nabla f(\\underline{x}_k)$\n",
    "2. Choose a distance $t$ to step along this direction\n",
    "3. Update the parameters $\\underline{x}_{k+1} = \\underline{x}_k + t \\underline{s}$\n",
    "\n",
    "### 2.a. Define the derivative function\n",
    "\n",
    "Fill in the code below to define a function `df` that returns the derivative of the Buckingham potential function at distance $r$. You'll need to first compute the derivative by hand, then code it in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the derivative of the Buckingham potential as a function of r\n",
    "\n",
    "def df(r):\n",
    "    \"\"\"\n",
    "    Returns the derivative of the Buckingham potential as a function of the distance r.\n",
    "    We set V_0 and sigma = 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set V_0 and sigma\n",
    "    \n",
    "    V_0   = 1\n",
    "    sigma = 1\n",
    "    \n",
    "    # Compute the derivative and return\n",
    "    \n",
    "    return  # FILL THIS IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b. Code the steepest descent algorithm\n",
    "\n",
    "Fill in the code below to define a function `steepest_descent` that uses the steepest descent algorithm to find the minimum of a function. The input to the function is the derivative function, `df`, and the starting value, `x0`. This problem is simple enough that we can choose a constant step size $t = 0.1$ and obtain fairly good results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepest_descent(df, x0):\n",
    "    \"\"\"\n",
    "    Run the steepest descent algorithm to find the minimum of the function whose gradient is df.\n",
    "    The starting value for the function is x0.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the system\n",
    "    \n",
    "    epsilon  = 0.0001  # Stopping condition -- end when |df/dx| < epsilon \n",
    "    max_iter = 100     # Maximum number of iterations\n",
    "    it       = 0       # Current iteration\n",
    "    \n",
    "    x    = x0     # Current parameter value\n",
    "    dfdx =  # FILL THIS IN, Initial value of the derivative\n",
    "    \n",
    "    # Report status\n",
    "    print('iter\\tx\\tdf/dx')\n",
    "    \n",
    "    \n",
    "    # Execute the steepest descent algorithm\n",
    "    \n",
    "    while np.fabs(dfdx)>=epsilon and it<max_iter:\n",
    "    \n",
    "        # Report status\n",
    "        print('%d\\t%.4f\\t%.4f' % (it, x, dfdx))\n",
    "\n",
    "        # Choose the step direction\n",
    "        s =  # FILL THIS IN\n",
    "\n",
    "        # Choose how far to step in that direction\n",
    "        t  = 0.1\n",
    "\n",
    "        # Update the parameters\n",
    "        x =  # FILL THIS IN\n",
    "\n",
    "        # Update the derivative\n",
    "        dfdx =  # FILL THIS IN\n",
    "\n",
    "        # Update the iteration counter\n",
    "        it += 1\n",
    "        \n",
    "\n",
    "    # Return the result\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find the minimum\n",
    "\n",
    "Now that we've defined the steepest descent algorithm, the next step is to run it and find the minimum of the Buckingham potential.\n",
    "\n",
    "### 3.a. Run the steepest descent algorithm\n",
    "\n",
    "Fill in the code to run the steepest descent algorithm. We'll start at an initial value of $r = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the starting position\n",
    "\n",
    "x0 =  # FILL THIS IN\n",
    "\n",
    "\n",
    "# Run steepest descent\n",
    "\n",
    "x_min =  # FILL THIS IN, use your steepest_descent function to find the minimum\n",
    "\n",
    "\n",
    "# Print the results\n",
    "\n",
    "print('Found the minimum at r = %.4f' % x_min)\n",
    "print('At this point the value of the potential is V(r) = %.4f' % buckingham(x_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b. Analyze the results\n",
    "\n",
    "Compare your results from from 3.a. to the plot you made in 1.b. Does the result appear to be correct? Are you sure that this is the global minimum of the function? Fill in your response in the Markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FILL THIS IN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c. Pathological results\n",
    "\n",
    "Copy your code from part 3.a. and run it again, but this time set `x0 = 0.68`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# < Your code from 3.a. here! Remember to change x0. >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.d. Explain what went wrong\n",
    "\n",
    "The value of the \"minimum\" that you find in 3.c. above should be much larger than the value that you got in 3.a. You can also verify that the value of the function at that distance is higher than in 3.a.\n",
    "\n",
    "In the Markdown cell below, explain why we find the wrong result in this case. What changes could you make to our optimization algorithm to prevent this from happening? Remember that there is no one correct answer here -- there are many possible strategies that we could take to avoid these errors. How would you approach a problem like this if you encountered it in your research?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FILL THIS IN**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
